{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96290624-c9cf-4e9c-9388-a3861385db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import unicodedata\n",
    "import pickle\n",
    "\n",
    "#load decoding dictionaries\n",
    "with open('itos_BPE.pkl', 'rb') as file:\n",
    "    itos = pickle.load(file)\n",
    "\n",
    "\n",
    "#define function that decodes numbers to texts\n",
    "def decode(ids):\n",
    "    text = \"\".join(itos[idx] for idx in ids)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8196948b-d969-466b-9fd1-35a862539351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "## Define the transformer structure\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split =='train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "    \n",
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            X, Y = X.to(device), Y.to(device)            \n",
    "            logits, loss = model(X,Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch('val')\n",
    "        X, Y = X.to(device), Y.to(device)            \n",
    "        logits, loss = model(X,Y)\n",
    "        losses[k] = loss.item()\n",
    "    val_loss = losses.mean()\n",
    "    model.train()\n",
    "    return val_loss\n",
    "            \n",
    "# class Head(nn.Module):\n",
    "#     def __init__(self, head_size):\n",
    "#         super().__init__()\n",
    "#         self.key = nn.Linear(n_embed, head_size, bias = False)\n",
    "#         self.query = nn.Linear(n_embed, head_size, bias = False)\n",
    "#         self.value = nn.Linear(n_embed, head_size, bias = False)\n",
    "\n",
    "#         self.register_buffer('tril',torch.tril(torch.ones(block_size, block_size)))\n",
    "#         self.dropout= nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         B,T,C = x.shape\n",
    "            \n",
    "#         k = self.key(x) #(B,T, head_size)\n",
    "#         q = self.query(x)\n",
    "#         v = self.value(x)\n",
    "        \n",
    "#         wei  = q @ k.transpose(-2,-1) * C**-0.5 #transpose along the last two dimensions, i.e. T and head_size \n",
    "#                                                         #(dot product sums over head_size indices)\n",
    "#                                         # (B,T, head_size) @  (B, head_size, T) -> (B,T, T)\n",
    "#         tril = torch.tril(torch.ones(T,T))\n",
    "#         wei = wei.masked_fill(tril == 0, float('-inf') )\n",
    "#         wei = F.softmax(wei, dim=-1)\n",
    "#         wei = self.dropout(wei)\n",
    "#         out = wei @ v\n",
    "        \n",
    "#         return out\n",
    "        \n",
    "class Head(nn.Module):#modified from above so that 'tril' tensor is always on the same device\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei @ v\n",
    "        return out        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(n_embed, 4*n_embed),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(4*n_embed, n_embed),\n",
    "                    nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self,n_embed, num_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // num_heads\n",
    "        self.sa = MultiHeadAttention(num_heads, head_size) #sa = self attention\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)  #LayerNorm also contains trainable parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa( self.ln1(x) ) #skip/residual connections\n",
    "        x = x + self.ffwd(  self.ln2(x)  )\n",
    "        return x\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(\n",
    "                    *[Block(n_embed, num_heads ) for _ in range(n_layers)],\n",
    "                    nn.LayerNorm(n_embed),\n",
    "        )\n",
    "        #self.sa_head = MultiHeadAttention(4, n_embed//4)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "\n",
    "        B, T = idx.shape\n",
    "        tok_emd  = self.token_embedding_table(idx)\n",
    "        pos_emd = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x= tok_emd + pos_emd\n",
    "        x = self.blocks(x)\n",
    "        x = self.ffwd(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "    \n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim =1)\n",
    "        return idx\n",
    "        \n",
    "    def generate_one_poem(self):\n",
    "        idx =  torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "        while True:\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim =1)\n",
    "            if idx_next.item() == 1:\n",
    "                break\n",
    "        return idx\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ce65b1f-e0e7-4b43-8b2c-697fa14db32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing model complete.\n",
      "The model has 7318952 trainable parameters.\n",
      "Embeding dimension = 216,\n",
      "Context length = 500,\n",
      "number of heads per layer = 6,\n",
      "number of layers = 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "vocab_size = len(itos)\n",
    "block_size = 500\n",
    "n_embed = 216\n",
    "num_heads = 6\n",
    "n_layers= 6\n",
    "m = BigramLanguageModel().to(device)\n",
    "\n",
    "#model_path = 'nano_tang_poem_layer6_context40_nebd64_nhead4.pt' \n",
    "# model_path = 'nano_tang_poem_layer6_context80_nebd64_nhead4.pt' \n",
    "# model_path = 'nano_tang_poem_layer8_context80_nebd64_nhead4.pt' # 1423780 trainable parameters\n",
    "# model_path = 'nano_tang_poem_layer10_context80_nebd64_nhead4.pt' # 1523364 trainable parameters.\n",
    "#model_path = 'nano_tang_poem_layer10_context80_nebd96_nhead8.pt' #2674436 trainable parameters\n",
    "\n",
    "#model_path = 'nano_tang_poem_BPE_layer10_context80_nebd96_nhead8.pt' #2741600 trainable parameters\n",
    "# model_path = 'nano_tang_poem_BPE_layer14_context80_nebd96_nhead8.pt' #3187808 trainable parameters # locally this costs 2.9GB MEM, 97%GPU and 87%CPU\n",
    "# model_path = 'nano_tang_poem_BPE_layer10_context500_nebd180_nhead6.pt' #7,144,460 trainable parameters \n",
    "# model_path = 'nano_tang_poem_BPE_layer4_context500_nebd252_nhead6.pt' #7,734,068 trainable parameters \n",
    "# model_path = 'nano_tang_poem_BPE_layer5_context500_nebd300_nhead6.pt' #11,095,100 trainable parameters \n",
    "# model_path = 'nano_tang_poem_BPE_layer4_context700_nebd384_nhead6.pt' #14,696,384 trainable parameters \n",
    "model_path = 'nano_tang_poem_BPE_layer6_context500_nebd216_nhead6.pt' #7,318,952   trainable parameters \n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    m.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    print(f\"Load existing model complete.\")\n",
    "else:\n",
    "    print(\"Creat new model weights file\")\n",
    "\n",
    "print(f\"The model has {num_params} trainable parameters.\")\n",
    "print(f\"Embeding dimension = {n_embed},\\nContext length = {block_size},\\nnumber of heads per layer = {num_heads},\\nnumber of layers = {n_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57a4f1ae-f9f0-470f-b988-25bda5579dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 0\n",
      "Using model:  nano_tang_poem_BPE_layer6_context500_nebd216_nhead6.pt\n",
      "<相裏題樂宮|席上天中布錦筵，銀瓶外上白鹽蓮。笙歌旋入新腰曲，鸞鳳高飛暫步前。洛水春生小齋院，日星鉤在小亭筵。五更朝夕仙郎樂，相次斜橋下荔筵。>\n",
      "<早春看花|雲重遍游長路過，蕭索春風意更多。百花紅滴魂難盡，一雁飛多語未多。莫道將何長薄俗，援毫深紫到三河。>\n",
      "<還舊居答元渚鏡|皎皎水榭蝶，萎妍春姿豔。高無嶧陽孫，留著西廂閣。丹桂羞兩疏，青藍擲持贈。客方複明朝，蘭蕙春蘭地。自言霜海材，衛惠徒有致。>\n",
      "<宣文玉京吟|陶公雖稱久，舊學國人亡。棄置十洲側，嘗對千山香。陸郎饒女貌，自美漁陽鄉。憶昔獻可移，手種生城荒。驪魚釁未掇，采貨檀已荒。仁義雖如此，黃公豈不忘。於賢寂相賴，盡室堪結芳。>\n",
      "<朱藤杖，誦詩以寄魯望|風霜秋節勁，雲雪未重輪。爵識床頭倚，心關漉酒巾。風消無睡出，雪積算心因。怪得從夫學，崖花更問身。>\n",
      "<雜曲歌辭：古別離|少婦怨春罷，去年妝鏡早。尚有別離心，相思還自語。>\n",
      "<和韋令狐相公同幸韋嗣後庭送蜀郡省中諸公|萬里東遊問界遙，桂吟詩詠月為台。江山已斷將雕鶚，雲雨沾沾綴發蹄。城上綠林留賦罷，面前紅樹落新栽。由來即道情多阻，已有禪衣重上才。>\n",
      "<讀謝甫李|風起泬寥天，蒼蒼竹雪然。彩霏吟澗水，玉爽在池泉。竹護西齋靜，梧來北巷閑。豈能忘傲吏，隱幾遠囂然。>\n",
      "<謝室|度嶺勢似削，辭流面天涯。夜梅初識雪，舊酒不辭花。產業舊交舊，名高廢廟奢。蘆洲發夜浪，竹箭發晴霞。徒覺題詩處，不勞雙鬢華。>\n",
      "<贈竇三文|自從明代欲分麾，正在明廷似事稀。卻喜永嘉人勸好，讀書須薦我垂衣。等閒命好無名利，不敢吟先得示機。人伴先生知興善，坐看營上玉山歸。>\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "print(f'Seed = {seed}')\n",
    "print(f\"Using model:  {model_path}\")\n",
    "m.eval()\n",
    "for _ in range(10):\n",
    "    print(decode(m.generate_one_poem()[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba4016-5a5f-45a7-a6c0-dd815a331043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
