{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8196948b-d969-466b-9fd1-35a862539351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import unicodedata\n",
    "\n",
    "#import time\n",
    "\n",
    "with open('quan_tang_shi_tagged_complete.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "\n",
    "def classify_chinese_char(char):\n",
    "    if len(char) != 1:\n",
    "        return \"Not a single character\"\n",
    "    \n",
    "    # Check if it's a CJK character\n",
    "    if '\\u4e00' <= char <= '\\u9fff':\n",
    "        return \"Chinese character\"\n",
    "    \n",
    "    # Check if it's a Chinese punctuation\n",
    "    category = unicodedata.category(char)\n",
    "    if category.startswith('P'):\n",
    "        # Additional check for common Chinese punctuation not categorized as 'P'\n",
    "        if char in '。，、：；？！（）\"\"''': #will treat 《》 as \"other\" because it they only appear in titles and I have tagged the titile differently\n",
    "            return \"Chinese punctuation\"\n",
    "    \n",
    "    return \"Other\"\n",
    "\n",
    "# Test the function\n",
    "test_chars = chars\n",
    "tags = '<>|'\n",
    "non_chinese = []\n",
    "for char in test_chars:\n",
    "    if  classify_chinese_char(char) == \"Other\":\n",
    "        non_chinese.append(char)\n",
    "\n",
    "for nc in non_chinese:\n",
    "    if nc not in tags:  #don't remove tags from character list\n",
    "        text = text.replace(nc, \"\")  # removes some supurious non chinese characters in the train data, but not tags\n",
    "chars = sorted(list(set(text))) #cleaned up vocab list\n",
    "\n",
    "vocab_size = len(chars)\n",
    "\n",
    "chars_without_tags = chars.copy() #I will reserve special places for tags in the encoding\n",
    "for c in tags:\n",
    "    chars_without_tags.remove(c)\n",
    "    \n",
    "\n",
    "\n",
    "stoi = {ch:i+3 for i, ch in enumerate(chars_without_tags)}\n",
    "stoi['<'] = 0 #special token to denote the start of a poem\n",
    "stoi['>'] = 1 #special token to denote the end of a poem\n",
    "stoi['|'] = 2 #special token to separate the title and the body of a poem\n",
    "itos = {i+3:ch for i, ch in enumerate(chars_without_tags)}\n",
    "itos[0] = '<'\n",
    "itos[1] = '>'\n",
    "itos[2] = '|'\n",
    "\n",
    "\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i]for i in l])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "enc_txt = encode(text)\n",
    "data = torch.tensor(enc_txt, dtype = torch.long).to(device)\n",
    "n = int(0.9 *len(data))\n",
    "train_data= data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "torch.manual_seed(13997)\n",
    "batch_size = 96\n",
    "\n",
    "block_size = 500\n",
    "\n",
    "vocab_size = len(itos)\n",
    "n_embed = 216\n",
    "num_heads = 6\n",
    "dropout = 0.1\n",
    "n_layers= 5\n",
    "eval_iters = 100\n",
    "\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split =='train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "    \n",
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            X, Y = X.to(device), Y.to(device)            \n",
    "            logits, loss = model(X,Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch('val')\n",
    "        X, Y = X.to(device), Y.to(device)            \n",
    "        logits, loss = model(X,Y)\n",
    "        losses[k] = loss.item()\n",
    "    val_loss = losses.mean()\n",
    "    model.train()\n",
    "    return val_loss\n",
    "            \n",
    "\n",
    "        \n",
    "class Head(nn.Module):#modified from above so that 'tril' tensor is always on the same device\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        \n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei @ v\n",
    "        return out        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(n_embed, 4*n_embed),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(4*n_embed, n_embed),\n",
    "                    nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self,n_embed, num_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // num_heads\n",
    "        self.sa = MultiHeadAttention(num_heads, head_size) #sa = self attention\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa( self.ln1(x) ) #skip/residual connections\n",
    "        x = x + self.ffwd(  self.ln2(x)  )\n",
    "        return x\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(\n",
    "                    *[Block(n_embed, num_heads ) for _ in range(n_layers)],\n",
    "                    nn.LayerNorm(n_embed),\n",
    "        )\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "\n",
    "        B, T = idx.shape\n",
    "        tok_emd  = self.token_embedding_table(idx)\n",
    "        pos_emd = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x= tok_emd + pos_emd\n",
    "        x = self.blocks(x)\n",
    "        x = self.ffwd(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "    \n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim =1)\n",
    "        return idx\n",
    "        \n",
    "    def generate_one_poem(self):\n",
    "        idx =  torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "        while True:\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim =1)\n",
    "            if idx_next.item() == 1:\n",
    "                break\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce65b1f-e0e7-4b43-8b2c-697fa14db32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing model complete.\n",
      "The model has 6568998 trainable parameters.\n",
      "Embeding dimension = 216,\n",
      "Context length = 500,\n",
      "number of heads per layer = 6,\n",
      "number of layers = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiyang/Documents/venv/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "m = BigramLanguageModel().to(device)\n",
    "num_params = count_parameters(m)\n",
    "\n",
    "# model_path = 'nano_tang_poem_layer6_context40_nebd64_nhead4.pt' \n",
    "# model_path = 'nano_tang_poem_layer6_context80_nebd64_nhead4.pt' \n",
    "# model_path = 'nano_tang_poem_layer8_context80_nebd64_nhead4.pt' # 1423780 trainable parameters\n",
    "# model_path = 'nano_tang_poem_layer10_context80_nebd64_nhead4.pt' # 1,523,364 trainable parameters.\n",
    "# model_path = 'nano_tang_poem_layer10_context80_nebd96_nhead8.pt' #2,674,436 trainable parameters\n",
    "# model_path = 'nano_tang_poem_layer6_context500_nebd216_nhead6.pt' #7,131,030 trainable parameters\n",
    "# model_path = 'nano_tang_poem_layer6_context500_nebd252_nhead6.pt' #9,044,034 trainable parameters\n",
    "# model_path = 'nano_tang_poem_layer7_context500_nebd252_nhead6.pt' #9,808,602trainable parameters\n",
    "# model_path = 'nano_tang_poem_layer7_context500_nebd300_nhead6.pt' #13,000,266 trainable parameters\n",
    "# model_path = 'nano_tang_poem_layer12_context500_nebd252_nhead6.pt' #13,631,442 trainable parameters.\n",
    "# model_path = 'nano_tang_poem_layer4_context500_nebd216_nhead6.pt'  #6,006,966 trainable parameters.\n",
    "model_path = 'nano_tang_poem_layer5_context500_nebd216_nhead6.pt'  #6,568,998 trainable parameters.\n",
    "if os.path.exists(model_path):\n",
    "    m.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    print(f\"Load existing model complete.\")\n",
    "else:\n",
    "    print(\"Creat new model weights file\")\n",
    "\n",
    "print(f\"The model has {num_params} trainable parameters.\")\n",
    "print(f\"Embeding dimension = {n_embed},\\nContext length = {block_size},\\nnumber of heads per layer = {num_heads},\\nnumber of layers = {n_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b4dacd-4075-4ff1-bce0-e1e2d5a2bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_loss = torch.log(torch.tensor(vocab_size)).item()\n",
    "train_loss_list = [initial_loss]\n",
    "val_loss_list = [initial_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6d5860-4a7d-42fc-85a3-fdaf8d47ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train loss: 3.743562698364258 | validation loss: 4.561662673950195\n",
      "50 train loss: 3.7233972549438477 | validation loss: 4.563227653503418\n",
      "100 train loss: 3.7321560382843018 | validation loss: 4.555168628692627\n",
      "150 train loss: 3.7369649410247803 | validation loss: 4.555629253387451\n",
      "200 train loss: 3.731658935546875 | validation loss: 4.553718090057373\n",
      "250 train loss: 3.7334487438201904 | validation loss: 4.547121524810791\n",
      "300 train loss: 3.735886573791504 | validation loss: 4.544760227203369\n",
      "350 train loss: 3.7369613647460938 | validation loss: 4.553102016448975\n",
      "400 train loss: 3.7328178882598877 | validation loss: 4.562074661254883\n",
      "450 train loss: 3.7376348972320557 | validation loss: 4.549578666687012\n",
      "500 train loss: 3.72126841545105 | validation loss: 4.558075904846191\n",
      "550 train loss: 3.7293529510498047 | validation loss: 4.549112796783447\n",
      "600 train loss: 3.7228100299835205 | validation loss: 4.548765182495117\n",
      "650 train loss: 3.718731164932251 | validation loss: 4.568052291870117\n",
      "700 train loss: 3.719451904296875 | validation loss: 4.553056240081787\n",
      "750 train loss: 3.7245607376098633 | validation loss: 4.56292200088501\n",
      "800 train loss: 3.7255055904388428 | validation loss: 4.564550399780273\n",
      "850 train loss: 3.716489553451538 | validation loss: 4.549867153167725\n",
      "900 train loss: 3.7153799533843994 | validation loss: 4.558396339416504\n",
      "950 train loss: 3.7186694145202637 | validation loss: 4.546797752380371\n",
      "1000 train loss: 3.7159202098846436 | validation loss: 4.552374362945557\n",
      "1050 train loss: 3.720858573913574 | validation loss: 4.552789211273193\n",
      "1100 train loss: 3.7132019996643066 | validation loss: 4.550009250640869\n",
      "1150 train loss: 3.7094082832336426 | validation loss: 4.54977560043335\n",
      "1200 train loss: 3.7173759937286377 | validation loss: 4.554314136505127\n",
      "1250 train loss: 3.712883949279785 | validation loss: 4.549911022186279\n",
      "1300 train loss: 3.7070488929748535 | validation loss: 4.563797473907471\n",
      "1350 train loss: 3.7115530967712402 | validation loss: 4.559637546539307\n",
      "1400 train loss: 3.708073139190674 | validation loss: 4.559133529663086\n",
      "1450 train loss: 3.705650568008423 | validation loss: 4.5527801513671875\n",
      "1500 train loss: 3.6938130855560303 | validation loss: 4.568342685699463\n",
      "1550 train loss: 3.707991361618042 | validation loss: 4.545248508453369\n",
      "1600 train loss: 3.697080373764038 | validation loss: 4.550725936889648\n",
      "1650 train loss: 3.712001323699951 | validation loss: 4.559119701385498\n",
      "1700 train loss: 3.7028849124908447 | validation loss: 4.541174411773682\n",
      "1750 train loss: 3.694767475128174 | validation loss: 4.555975914001465\n",
      "1800 train loss: 3.6999948024749756 | validation loss: 4.550518989562988\n",
      "1850 train loss: 3.701199531555176 | validation loss: 4.5510640144348145\n",
      "1900 train loss: 3.694854974746704 | validation loss: 4.557989120483398\n",
      "1950 train loss: 3.695704460144043 | validation loss: 4.551790714263916\n",
      "2000 train loss: 3.695646286010742 | validation loss: 4.54986572265625\n",
      "2050 train loss: 3.696043014526367 | validation loss: 4.553908348083496\n",
      "2100 train loss: 3.6978137493133545 | validation loss: 4.553117752075195\n",
      "2150 train loss: 3.6880669593811035 | validation loss: 4.55286169052124\n",
      "2200 train loss: 3.6960649490356445 | validation loss: 4.552168369293213\n",
      "2250 train loss: 3.6937835216522217 | validation loss: 4.5464935302734375\n",
      "2300 train loss: 3.6908249855041504 | validation loss: 4.533407688140869\n",
      "2350 train loss: 3.6916558742523193 | validation loss: 4.550922393798828\n",
      "2400 train loss: 3.682821035385132 | validation loss: 4.546991348266602\n",
      "2450 train loss: 3.6848227977752686 | validation loss: 4.544358253479004\n",
      "2500 train loss: 3.682652473449707 | validation loss: 4.551865100860596\n",
      "2550 train loss: 3.684238910675049 | validation loss: 4.547629356384277\n",
      "2600 train loss: 3.685800790786743 | validation loss: 4.547806262969971\n",
      "2650 train loss: 3.6827597618103027 | validation loss: 4.5574727058410645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_layer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_context\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblock_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nebd\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_embed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nhead\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     55\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss_layer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_context\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblock_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nebd\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_embed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nhead\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     59\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    106\u001b[0m         X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device)            \n\u001b[1;32m    107\u001b[0m         logits, loss \u001b[38;5;241m=\u001b[39m model(X,Y)\n\u001b[0;32m--> 108\u001b[0m         losses[k] \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     out[split] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    110\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_iters =6001\n",
    "eval_interval = 300\n",
    "learning_rate = 1* 1e-3\n",
    "m.train()\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr =learning_rate)\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for steps in range(max_iters):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    if steps % eval_interval ==0:\n",
    "        train_loss = estimate_loss(m)['train']\n",
    "        with open(f'train_loss_layer{n_layers}_context{block_size}_nebd{n_embed}_nhead{num_heads}.txt', 'a') as file:\n",
    "            file.write(f\"{train_loss}\\n\")\n",
    "            \n",
    "        val_loss = estimate_loss(m)['val']\n",
    "        with open(f'val_loss_layer{n_layers}_context{block_size}_nebd{n_embed}_nhead{num_heads}.txt', 'a') as file:\n",
    "            file.write(f\"{val_loss}\\n\")\n",
    "            \n",
    "        if val_loss < min(val_loss_list):\n",
    "            torch.save(m.state_dict(), model_path)\n",
    "        \n",
    "        train_loss_list.append(train_loss.item())\n",
    "        val_loss_list.append(val_loss.item())\n",
    "        \n",
    "        \n",
    "        print(steps, f'train loss: {train_loss} | validation loss: {val_loss}')\n",
    "        \n",
    "    logits, loss = m(xb, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if val_loss < 4.6:\n",
    "            break\n",
    "    \n",
    "\n",
    "max_iters =6001\n",
    "eval_interval = 50\n",
    "learning_rate = 1* 1e-4\n",
    "m.train()\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr =learning_rate)\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "\n",
    "for steps in range(max_iters):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    if steps % eval_interval ==0:\n",
    "        train_loss = estimate_loss(m)['train']\n",
    "        with open(f'train_loss_layer{n_layers}_context{block_size}_nebd{n_embed}_nhead{num_heads}.txt', 'a') as file:\n",
    "            file.write(f\"{train_loss}\\n\")\n",
    "            \n",
    "        val_loss = estimate_loss(m)['val']\n",
    "        with open(f'val_loss_layer{n_layers}_context{block_size}_nebd{n_embed}_nhead{num_heads}.txt', 'a') as file:\n",
    "            file.write(f\"{val_loss}\\n\")\n",
    "            \n",
    "        if val_loss < min(val_loss_list):\n",
    "            torch.save(m.state_dict(), model_path)\n",
    "        \n",
    "        train_loss_list.append(train_loss.item())\n",
    "        val_loss_list.append(val_loss.item())\n",
    "        \n",
    "        \n",
    "        print(steps, f'train loss: {train_loss} | validation loss: {val_loss}')\n",
    "    logits, loss = m(xb, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769bc5bd-f383-4503-85e6-c24b856bbfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed = 0\n",
      "using model:  nano_tang_poem_layer5_context500_nebd216_nhead6.pt\n",
      "<寒行台江|秦人聽琴譜，結子醉蘆花。城南宅已斷，吾子識何家。>\n",
      "<留別斛斯處士哭王尚書|年少中台哭，車來自使臣。壁荒猶在此，墳老尚寒新。怕哭兼村落，愁眠有客頻。思君空問所，歲月又行春。>\n",
      "<秋日曲江南樓宿龍處士東塘|惜別東溪望，雲山卷襪塵。寶瓶珊瑚樹，流沫滿西津。楚客思還爽，兒童笑子真。不知槎客去，相勸赴長津。>\n",
      "<七夕寄獨孤道部崔京|戈鋋遠去抵祁連，西國何曾薄結餘。若戀征書知己賤，無心自是望相吳。>\n",
      "<送於諫議赴鎮三台郎赴任郎中見贈之|出謝誰憐我渴閑，請君尋得到袁安。雲台應伏何天寵，客路無妨未擬看。今日排雲開諫樹，八行恩德賜秦官。>\n",
      "<淚下|長安宮闕土王台，今裏花開萬箱開。紫陌書名女郎去，九鐘花落嶺頭來。>\n",
      "<步楊主簿送遷感|淒淒迢迢行雨土，搖落猿啼秋雁悲。西陵故地霜何在，別後形容雪一枝。>\n",
      "<春日作|遠思空王詔，才達任家情。宦名宗子籍，禮樂亦淫情。即此奇方理，臨岐一任誠。仙舟把蘭浦，應念析雲情。>\n",
      "<題吳江|荊荊召吳君，流小離離席。泉邊蓮稍響，星浦蓮枝落。樹發歌黛多，雨臥桃李綠。夜來江上鶴，自正開澄浦。神女今雖始，青燈象成贈。憶昔知己稀，爾來投楚岫。仙人贈手劄，數宿魚龍轡。駐馬望北風，傾壺詠佳句。鄭衛浮靈岩，歸宵瀉金磬。群安有熟氛，碧天長閉目。曉入桂林間，幽遊田家夕。社滿嵐氣生，人傳何賈策。一駕三千里，窮秋兩岐路。我憶青雲家，前溪寒有月。今來值秋夜，淅瀝寒泉淚。清灘長甚深，青猿洗山夢。且酌此夜思，謬依循宦趣。>\n",
      "<成王山人張說五月九刻韻|璧林十餘裏，我愛世界皆。不知寸祿信，飲罷又無心。神速卿相如，不與高樹陰。越鳥為誠性，楚人為改心。琴弄雕刻跡，酒尊髭所深。高窗永言古，芳心多苦吟。茶餘側耳目，酒氣暢相尋。人藥滿中園，蔬羹知巳琴。是物茹雲獷，繰饑枉生針。一曲古無味，空交蔬與心。良願魏子思，過江蓴複深。>\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "print(f'Seed = {seed}')\n",
    "print(f\"Using model:  {model_path}\")\n",
    "m.eval()\n",
    "for _ in range(10):\n",
    "    print(decode(m.generate_one_poem()[0].tolist()))#loss at 4.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78292f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a342c-c1b3-4311-bc8e-0d30623e07f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
